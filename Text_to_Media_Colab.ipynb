{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Text-to-Media: Ultimate Video Generation (Colab, Local Upload)\n",
        "\n",
        "This Colab sets up and runs the full video pipeline using a project zip you upload from your local machine.\n",
        "\n",
        "Pipeline: Stable Diffusion → AnimateDiff → StableSR → RealESRGAN → FILM → FFmpeg\n",
        "\n",
        "Instructions:\n",
        "1) Zip your local `text-to-media-app` folder.\n",
        "2) Run the upload cell below and select the zip.\n",
        "3) Run the install and model download cells.\n",
        "4) Run the test generation cell and download the MP4.\n",
        "\n",
        "Notes:\n",
        "- Requires a Colab GPU (T4/A100). CPU is not recommended.\n",
        "- Downloads are large (10–20+ GB). Ensure runtime time/storage.\n",
        "- Outputs saved to `/content/text-to-media-app/outputs/videos`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Check GPU\n",
        "nvidia-smi || echo \"No NVIDIA GPU detected (CPU runtime).\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload your zipped local project (text-to-media-app.zip)\n",
        "from google.colab import files\n",
        "import os, shutil, zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "upload = files.upload()  # Select your project zip\n",
        "zip_name = next(iter(upload.keys()))\n",
        "print('Uploaded:', zip_name)\n",
        "\n",
        "# Prepare workspace\n",
        "root = Path('/content')\n",
        "workdir = root / 'text-to-media-app'\n",
        "if workdir.exists():\n",
        "    shutil.rmtree(workdir)\n",
        "workdir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Extract zip into /content\n",
        "with zipfile.ZipFile(zip_name, 'r') as z:\n",
        "    z.extractall(root)\n",
        "\n",
        "# If the zip contains a top-level folder, ensure path normalization\n",
        "if not workdir.exists():\n",
        "    # Try to find extracted folder\n",
        "    cands = [p for p in root.iterdir() if p.is_dir() and p.name.startswith('text-to-media-app')]\n",
        "    if cands:\n",
        "        cands[0].rename(workdir)\n",
        "\n",
        "print('Workspace ready at:', workdir)\n",
        "!ls -la /content/text-to-media-app\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# System deps\n",
        "apt-get update -y && apt-get install -y ffmpeg git-lfs\n",
        "\n",
        "git lfs install\n",
        "\n",
        "# Ensure we are in the uploaded workspace\n",
        "cd /content/text-to-media-app\n",
        "pwd && ls -la\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Python deps\n",
        "python -m pip install -U pip setuptools wheel\n",
        "python -m pip install --extra-index-url https://download.pytorch.org/whl/cu121 -r backend/requirements.txt\n",
        "\n",
        "# Reduce TF logs\n",
        "export TF_CPP_MIN_LOG_LEVEL=2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download models (priority first)\n",
        "cd /content/text-to-media-app/scripts\n",
        "python download-models.py --priority || true\n",
        "python download-models.py --list || true\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify complete model downloads before running\n",
        "from pathlib import Path\n",
        "import sys, os\n",
        "\n",
        "ROOT = Path('/content')\n",
        "MODELS = ROOT / 'models'\n",
        "SD_DIR = MODELS / 'image' / 'stable-diffusion'\n",
        "AD_DIR = MODELS / 'video' / 'animatediff'\n",
        "AD_ADAPTER_DIR = AD_DIR / 'motion_adapter'\n",
        "SR_DIR = MODELS / 'upscaling' / 'stablesr'\n",
        "REALESRGAN_DIR = MODELS / 'upscaling' / 'realesrgan'\n",
        "FILM_DIR = MODELS / 'interpolation' / 'film'\n",
        "\n",
        "errors = []\n",
        "\n",
        "# Stable Diffusion checks\n",
        "if not SD_DIR.exists():\n",
        "    errors.append('Stable Diffusion directory missing')\n",
        "else:\n",
        "    req_dirs = ['text_encoder','unet','vae','scheduler','tokenizer']\n",
        "    for d in req_dirs:\n",
        "        if not (SD_DIR / d).exists():\n",
        "            errors.append(f'Stable Diffusion missing dir: {d}')\n",
        "    # require at least one weight file\n",
        "    has_sd_weights = any(list((SD_DIR).rglob(ext)) for ext in ['*.safetensors','*.bin','*.ckpt'])\n",
        "    if not has_sd_weights:\n",
        "        errors.append('Stable Diffusion weights not found')\n",
        "\n",
        "# AnimateDiff checks\n",
        "if not AD_DIR.exists():\n",
        "    errors.append('AnimateDiff repo missing')\n",
        "if not AD_ADAPTER_DIR.exists():\n",
        "    errors.append('AnimateDiff motion_adapter missing')\n",
        "else:\n",
        "    has_adapt_weights = any(list(AD_ADAPTER_DIR.rglob(ext)) for ext in ['*.safetensors','*.bin'])\n",
        "    if not has_adapt_weights:\n",
        "        errors.append('AnimateDiff motion adapter weights missing')\n",
        "\n",
        "# StableSR assets (x4 upscaler snapshot used as dependency assets)\n",
        "if not SR_DIR.exists():\n",
        "    errors.append('StableSR upscaler assets missing')\n",
        "\n",
        "# RealESRGAN weights\n",
        "req_realesr = [\n",
        "    REALESRGAN_DIR / 'RealESRGAN_x4plus.pth',\n",
        "    REALESRGAN_DIR / 'RealESRGAN_x4plus_anime_6B.pth'\n",
        "]\n",
        "for p in req_realesr:\n",
        "    if not p.exists() or p.stat().st_size == 0:\n",
        "        errors.append(f'RealESRGAN weight missing: {p.name}')\n",
        "\n",
        "# FILM repo presence (weights come from TF Hub at runtime)\n",
        "if not FILM_DIR.exists():\n",
        "    errors.append('FILM repository not found')\n",
        "\n",
        "if errors:\n",
        "    print('❌ Model verification failed:')\n",
        "    for e in errors:\n",
        "        print(' -', e)\n",
        "    raise SystemExit('Please re-run the download cell; required model files are missing.')\n",
        "else:\n",
        "    print('✅ All required model files verified.')\n",
        "\n",
        "# Run a short end-to-end generation with the Ultimate pipeline\n",
        "import os, sys, asyncio\n",
        "from pathlib import Path\n",
        "\n",
        "%cd /content/text-to-media-app\n",
        "sys.path.append('/content/text-to-media-app/backend')\n",
        "\n",
        "from backend.utils.gpu_detector import GPUDetector\n",
        "from backend.models.video_generator import VideoGenerator\n",
        "\n",
        "info = GPUDetector().gpu_info\n",
        "print('GPU info:', info)\n",
        "\n",
        "async def run():\n",
        "    gen = VideoGenerator(info)\n",
        "    ok = await gen.load_model('ultimate-pipeline')\n",
        "    if not ok:\n",
        "        raise RuntimeError('Failed to load ultimate pipeline')\n",
        "\n",
        "    prompts = [\n",
        "        'A cinematic cyberpunk city at night, neon lights, rain reflections, flying cars, holograms, highly detailed',\n",
        "        'A serene forest with fireflies at dusk, volumetric lighting, ultra-detailed, macro style',\n",
        "        'An astronaut surfing waves on an alien ocean under two moons, dramatic lighting, 4k detail'\n",
        "    ]\n",
        "\n",
        "    outputs = []\n",
        "    for p in prompts:\n",
        "        out_path = await gen.generate(\n",
        "            prompt=p,\n",
        "            model_name='ultimate-pipeline',\n",
        "            duration=3,\n",
        "            output_format='mp4',\n",
        "            preset='ultra-fast',\n",
        "            fps=8,\n",
        "            num_inference_steps=20,\n",
        "            motion_scale=1.2,\n",
        "        )\n",
        "        print('Generated:', out_path)\n",
        "        outputs.append(out_path)\n",
        "    return outputs\n",
        "\n",
        "outs = asyncio.run(run())\n",
        "print('Outputs:', outs)\n",
        "\n",
        "# Confirm files exist\n",
        "for o in outs:\n",
        "    assert Path(o).exists(), f'Output not found: {o}'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download generated videos\n",
        "from google.colab import files\n",
        "import glob\n",
        "\n",
        "videos = sorted(glob.glob('/content/text-to-media-app/outputs/videos/*.mp4'))\n",
        "print('Found videos:', videos[-5:])\n",
        "for v in videos[-3:]:  # offer last 3 for download\n",
        "    try:\n",
        "        files.download(v)\n",
        "    except Exception as e:\n",
        "        print('Download failed for', v, e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Text-to-Media: Ultimate Video Generation (Google Colab)\n",
        "\n",
        "This Colab sets up the full video pipeline:\n",
        "- Stable Diffusion → AnimateDiff → StableSR → RealESRGAN → FILM → FFmpeg\n",
        "- Downloads all required models into the runtime\n",
        "- Runs a short end-to-end generation and provides a downloadable MP4\n",
        "\n",
        "Notes:\n",
        "- Colab T4/A100 GPUs are supported. CPU is not recommended.\n",
        "- Total downloads can be large (10–20+ GB). Ensure you have session time and storage.\n",
        "- Output is saved under `/content/text-to-media-app/outputs/videos`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Check GPU\n",
        "nvidia-smi || echo \"No NVIDIA GPU detected (CPU runtime).\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# System deps\n",
        "apt-get update -y && apt-get install -y ffmpeg git-lfs\n",
        "\n",
        "# Enable Git LFS\n",
        "git lfs install\n",
        "\n",
        "# Clone repo (shallow)\n",
        "cd /content\n",
        "if [ ! -d \"/content/text-to-media-app\" ]; then\n",
        "  git clone --depth 1 https://github.com/your-org-or-user/text-to-media-app.git\n",
        "fi\n",
        "cd /content/text-to-media-app\n",
        "\n",
        "# Optional: pull latest\n",
        "git pull || true\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Python deps (Colab GPU CUDA 12.1)\n",
        "python -m pip install -U pip setuptools wheel\n",
        "# Prefer PyTorch CUDA wheels if available in this runtime\n",
        "python -m pip install --extra-index-url https://download.pytorch.org/whl/cu121 -r backend/requirements.txt\n",
        "\n",
        "# Reduce TF logs\n",
        "export TF_CPP_MIN_LOG_LEVEL=2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Download models (priority first to save time)\n",
        "cd /content/text-to-media-app/scripts\n",
        "python download-models.py --priority || true\n",
        "# Verify what we have\n",
        "python download-models.py --list || true\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run a short end-to-end generation with the Ultimate pipeline\n",
        "import os, sys, asyncio, json, glob\n",
        "from pathlib import Path\n",
        "\n",
        "%cd /content/text-to-media-app\n",
        "sys.path.append('/content/text-to-media-app/backend')\n",
        "\n",
        "from backend.utils.gpu_detector import GPUDetector\n",
        "from backend.models.video_generator import VideoGenerator\n",
        "\n",
        "# Detect GPU/device\n",
        "info = GPUDetector().gpu_info\n",
        "print('GPU info:', info)\n",
        "\n",
        "async def run():\n",
        "    gen = VideoGenerator(info)\n",
        "    # Load the ultimate pipeline\n",
        "    ok = await gen.load_model('ultimate-pipeline')\n",
        "    if not ok:\n",
        "        raise RuntimeError('Failed to load ultimate pipeline')\n",
        "\n",
        "    prompt = 'A cinematic cyberpunk city at night, neon lights, rain reflections, flying cars, holograms, highly detailed, dramatic lighting'\n",
        "    # Keep duration short (<= 3-4s) for Colab memory/time\n",
        "    out_path = await gen.generate(\n",
        "        prompt=prompt,\n",
        "        model_name='ultimate-pipeline',\n",
        "        duration=3,\n",
        "        output_format='mp4',\n",
        "        preset='ultra-fast',\n",
        "        fps=8,\n",
        "        num_inference_steps=20,\n",
        "        motion_scale=1.2,\n",
        "    )\n",
        "    return out_path\n",
        "\n",
        "out = asyncio.run(run())\n",
        "print('Output:', out)\n",
        "\n",
        "# Confirm file exists\n",
        "assert Path(out).exists(), 'Output video not found'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download the resulting video\n",
        "from google.colab import files\n",
        "from pathlib import Path\n",
        "import glob\n",
        "\n",
        "candidates = sorted(glob.glob('/content/text-to-media-app/outputs/videos/*.mp4'))\n",
        "print('Found videos:', candidates[-3:])\n",
        "if candidates:\n",
        "    files.download(candidates[-1])\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
